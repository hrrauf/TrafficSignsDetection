{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import load_model\n",
    "import keras\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import timeit\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize List to Append each data file\n",
    "\n",
    "DATA_PATH = '/datasets/home/21/321/ee228sp20ta1/G36/'\n",
    "#'Different Data Files' for training,  validation adn test\n",
    "filenames=['processed_data.pickle', 'train.pickle']\n",
    "# i=0\n",
    "data=[]\n",
    "def show_data(data, num_exp):\n",
    "    '''\n",
    "    Display some random instances\n",
    "    of input data.\n",
    "    \n",
    "    Input:-\n",
    "    -----\n",
    "    data :  type(4-D array)\n",
    "        Input data in the form\n",
    "        of images\n",
    "        \n",
    "    '''\n",
    "    assert 0<=num_exp<=5\n",
    "\n",
    "    x=[np.array([i]) for i in np.arange(data.shape[0])]\n",
    "    rnd_ind = random.choices(x, k = num_exp)\n",
    "    images = (data[rnd_ind,:,:,:]).squeeze(1)\n",
    "    h_stack_image =np.hstack(images) # Getting Incorrect Images and Stacking\n",
    "                                 # them to print in one go\n",
    "    plt.figure(figsize = (30,6))\n",
    "    plt.imshow(h_stack_image, cmap='gray')    # Converting into unsigned integers for plt.imshow              \n",
    "    plt.xticks([])\n",
    "    plt.yticks([])  \n",
    "    \n",
    "    \n",
    "def show_hist(labels, status, color):\n",
    "    plt.hist(labels, bins = 43,color= color,rwidth= 0.9 )\n",
    "    plt.xlabel('Classes', fontsize = '15')\n",
    "    plt.ylabel('Frequency', fontsize = '15')\n",
    "    plt.title('Classes Distribution '+ status+ ' Preprocessing', fontsize = '15')\n",
    "    \n",
    "    \n",
    "for i in range(2):\n",
    "        file= os.path.join(DATA_PATH, filenames[i])\n",
    "        with open(file, 'rb') as f:\n",
    "             data.append(pickle.load(f, encoding='latin1'))  \n",
    "\n",
    "#Plotting classes distribution before  and after preprocessing       \n",
    "pro=data[0]['y_train'][:,None]\n",
    "pre=data[1]['labels'][:,None]\n",
    "plt.figure(figsize = (20,7))\n",
    "plt.subplot(1,2,1)\n",
    "show_hist(pre, 'Before', 'r')\n",
    "plt.subplot(1,2,2)\n",
    "show_hist(pro, 'After', 'g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dictionary of the stored csv files from each of the model fitting history\n",
    "def make_dict_model(net):\n",
    "    '''\n",
    "    Read csv file defined by the model name\n",
    "    Input\n",
    "    model name (string)\n",
    "    \n",
    "    Returns\n",
    "    dict{}\n",
    "    Keys:\n",
    "    epoch: Maximum number of epochs on which it was trained\n",
    "    indices: indices for plotting accuracy from 0 to epoch with step size = 10\n",
    "    vals: values of validation accuracy at those indices\n",
    "    train: maximum accuracy achieved on the training set\n",
    "    val:   maximum accuracy achieved on the validation set\n",
    "\n",
    "    '''\n",
    "    assert type(net)==str\n",
    "    indx=list(range(1,102,9))\n",
    "    vals=list(range(0,101,9))\n",
    "    dictionary={}\n",
    "    filename= './outputs/model_'+net+'.csv'\n",
    "    net=pd.read_csv(filename)\n",
    "   \n",
    "    if 'val_acc' in net.columns:\n",
    "        \n",
    "        dictionary={'epoch': len(net['val_acc']), 'indices':indx, \n",
    "                   'val_acc': net['val_acc'].iloc[vals], 'val':net['val_acc'][99], 'train':net['acc'][99]}\n",
    "    elif 'val_accuracy' in net.columns:\n",
    "         dictionary={'epoch': len(net['val_accuracy']), 'indices':indx, \n",
    "                   'val_acc': net['val_accuracy'].iloc[vals], 'val':net['val_accuracy'][99], 'train':net['accuracy'][99]}\n",
    "    else:\n",
    "        dictionary= {'epoch': len(net['val_output_accuracy']), 'indices':indx, \n",
    "        'val_acc': net['val_output_accuracy'].iloc[vals], 'val':net['val_output_accuracy'][99], 'train':net['output_accuracy'][99]}\n",
    "\n",
    "\n",
    "    return dictionary\n",
    "\n",
    "densenet_dict=make_dict_model('DensNet') \n",
    "resnet_dict=make_dict_model('ResNet') \n",
    "inception_dict=make_dict_model('GoogleNet') \n",
    "ours_dict=make_dict_model('new_impl')\n",
    "VGG19_dict=make_dict_model('VGG19')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make Scatter plot for validation accuracy\n",
    "plt.figure(figsize = (15,7))\n",
    "\n",
    "plt.scatter(densenet_dict['indices'], densenet_dict['val_acc'], marker= 'D',color= 'r', s= 100, label = 'DenseNet')\n",
    "plt.scatter(resnet_dict['indices'], resnet_dict['val_acc'], marker= '8',color= 'b', s= 90,label = 'ResNet')\n",
    "plt.scatter(ours_dict['indices'], ours_dict['val_acc'], marker= '*',color= 'y', s= 120,label = 'OurModel')\n",
    "plt.scatter(inception_dict['indices'], inception_dict['val_acc'], marker= '>', s= 80, color= 'darkslategray', label = 'Inceptionv1')\n",
    "plt.scatter(rnn_dict['indices'], rnn_dict['val_acc'], marker= 'd',color= 'darkred', s= 70,label = 'RNN')\n",
    "plt.scatter(VGG19_dict['indices'], VGG19_dict['val_acc'], marker= '<',color= 'maroon', s= 70,label = 'VGG-19')\n",
    "\n",
    "\n",
    "plt.xlabel('Epochs', fontsize =15)\n",
    "plt.ylabel('Test Accuracy', fontsize =15)\n",
    "plt.xlim([0,101])\n",
    "plt.ylim([0.85,1.00])\n",
    "plt.legend(fontsize=12)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make Line Plot for validation Accuracy\n",
    "'''\n",
    "Color Scheme\n",
    "        color=['forestgreen'],  label= 'Our Model\n",
    "        color=['magenta'],  label = 'VGG19'\n",
    "        color=['firebrick'], label= 'ResNet'\n",
    "        color=['goldenrod'], label = 'Densenet'\n",
    "        color=['darkorange'],label = 'Inception-V1'\n",
    "        color=['blue'],  label ='RNN'\n",
    "\n",
    "'''\n",
    "plt.figure(figsize = (9,7))\n",
    "\n",
    "plt.plot(densenet_dict['indices'], densenet_dict['val_acc'], marker= 'D',color= 'goldenrod', label = 'DenseNet')\n",
    "plt.plot(resnet_dict['indices'], resnet_dict['val_acc'], marker= '8',color= 'firebrick', label = 'ResNet')\n",
    "plt.plot(ours_dict['indices'], ours_dict['val_acc'], marker= '*',color= 'forestgreen', label = 'OurModel')\n",
    "plt.plot(inception_dict['indices'], inception_dict['val_acc'], marker= '>',  color= 'darkorange', label = 'Inceptionv1')\n",
    "plt.plot(rnn_dict['indices'], rnn_dict['val_acc'], marker= 'd',color= 'blue', label = 'RNN')\n",
    "plt.plot(VGG19_dict['indices'], VGG19_dict['val_acc'], marker= '<',color= 'm', label = 'VGG-19')\n",
    "\n",
    "\n",
    "plt.xlabel('Epochs', fontsize =15)\n",
    "plt.ylabel('Validation Accuracy', fontsize =15)\n",
    "plt.xlim([0,101])\n",
    "plt.ylim([0,1.1])\n",
    "plt.legend(fontsize=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Confusion Matrix plot from confusion matrix numpy array\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "#Make Histograms for showing train, test, validation accuracies of each model\n",
    "'''\n",
    "Color Scheme\n",
    "        color=['forestgreen'],  label= 'Our Model\n",
    "        color=['teal'],  label = 'VGG19'\n",
    "        color=['firebrick'], label= 'ResNet'\n",
    "        color=['goldenrod'], label = 'Densenet'\n",
    "        color=['darkorange'],label = 'Inception-V1'\n",
    "        color=['blue'],  label ='RNN'\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "kwargs = {'alpha':0.8, 'linestyle':':', 'linewidth':3, 'edgecolor':'k'}\n",
    "plt.bar(x=np.arange(0,6,1), height= 100*np.array([ours_dict['train'], VGG19_dict['train'], resnet_dict['train'],densenet_dict['train'] ,inception_dict['train'] ,rnn_dict['train']]), color=['forestgreen', 'teal','firebrick','goldenrod','darkorange', 'blue'], width = 0.9, **kwargs)\n",
    "plt.bar(x= np.arange(8,14,1), height= 100*np.array([ours_dict['val'], VGG19_dict['val'], resnet_dict['val'],densenet_dict['val'],  inception_dict['val'],rnn_dict['val']]),color=['forestgreen', 'teal','firebrick','goldenrod','darkorange', 'blue'], width = 0.9, **kwargs)\n",
    "\n",
    "plt.bar(x= 16, height=  0.9771*100, width = 0.9, color=['forestgreen'], **kwargs, label= 'Our Model')\n",
    "plt.bar(x=17, height=  0.9812*100, width = 0.9, color=['teal'], **kwargs, label = 'VGG19')\n",
    "plt.bar(x= 18, height= 0.9480*100, width = 0.9, color=['firebrick'], **kwargs, label= 'ResNet')\n",
    "plt.bar(x= 19, height= 0.9559*100, width = 0.9, color=['goldenrod'], **kwargs, label = 'Densenet')\n",
    "plt.bar(x=20, height=  0.9516*100, width = 0.9, color=['darkorange'], **kwargs, label = 'Inception-V1')\n",
    "plt.bar(x= 21, height=  0.89*100, width = 0.9, color=['blue'], **kwargs, label ='RNN')\n",
    "\n",
    "\n",
    "plt.xticks(np.arange(2.5,22,8), ['Training Accuracy', 'Validation Accuracy', 'Test Accuracy' ], fontsize = 20)\n",
    "\n",
    "plt.ylim([80,105])\n",
    "plt.ylabel('Accuracy(%)', fontsize = 20, color = 'k')\n",
    "plt.legend( fontsize = 15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Calculate evaluation time for each model for the whole test set\n",
    "model=tf.keras.models.load_model('model_ours_data')\n",
    "%timeit model.predict(data[0]['x_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg= load_model('./trained_models/model_VGG19_data')\n",
    "%timeit vgg.predict(data[0]['x_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn= load_model('./trained_models/model_RNN_data')\n",
    "%timeit rnn.predict(data[0]['x_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception= load_model('./trained_models/model_GoogleNet_data')\n",
    "%timeit inception.predict(data[0]['x_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception= tf.keras.models.load_model('./trained_models/model_ResNet_data')\n",
    "%timeit inception.predict(data[0]['x_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception= tf.keras.models.load_model('./trained_models/model_DensNet_data')\n",
    "%timeit inception.predict(data[0]['x_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot evaluation time for each of the model for the whole set in seconds\n",
    "'''\n",
    "Color Scheme\n",
    "        color=['forestgreen'],  label= 'Our Model\n",
    "        color=['teal'],  label = 'VGG19'\n",
    "        color=['firebrick'], label= 'ResNet'\n",
    "        color=['goldenrod'], label = 'Densenet'\n",
    "        color=['darkorange'],label = 'Inception-V1'\n",
    "        color=['blue'],  label ='RNN'\n",
    "\n",
    "'''\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "kwargs = {'alpha':0.8, 'linestyle':':', 'linewidth':3, 'edgecolor':'k'}\n",
    "plt.barh(width=[1.44,4.32, 4.37, 5.11,7.23, 15.4],  y=np.arange(6), \n",
    "         color=['forestgreen','teal','darkorange','firebrick', 'goldenrod', 'blue'], **kwargs)\n",
    "plt.yticks(np.arange(6), ['OurModel', 'VGG19', 'Inception-V1','ResNet','DenseNet', 'RNN'], fontsize = 15)\n",
    "plt.xlabel('Prediction Time (s)', fontsize = 15)\n",
    "plt.ylim([-0.5,5.5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Confusion Matrix for our model\n",
    "y=pd.read_csv('./outputs/our_model_prediction.csv')\n",
    "\n",
    "y_predict=y.iloc[0]\n",
    "y_test=y.iloc[1]\n",
    "  \n",
    "cmt=confusion_matrix(y_predict, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap='YlGnBu')\n",
    "    plt.title(title)\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"red\" if cm[i, j] > thresh else \"black\", fontsize = 11)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label', fontsize = 15)\n",
    "    plt.xlabel('Predicted label', fontsize = 15)\n",
    "    \n",
    "plt.figure(figsize=(12, 12))\n",
    "plot_confusion_matrix(cmt, classes=np.arange(43))\n",
    "plt.title('Confusion Plot for our Model', fontsize='15')\n",
    "plt.savefig('confusion_matrix.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
